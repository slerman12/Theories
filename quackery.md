> This starts disingenuously stupid and becomes smart.

I’m just going to try to organize my thoughts. How do we know that germs cause disease? Germs and disease coincide at the same time and location, and therefore we know with high probability that germs cause disease. The coinciding relationship between germs and disease is not just measured once, but reproducibly and consistently every time disease is measured. Where we find disease, we find germs. Those germs perhaps move around in specific patterns and coincide with “reactions” where our measuring tools measure a transformation from one pattern to another, in a sequence that coincides with the measurement of disease. That’s how we know germs cause disease. It is worth noting that this isn’t deductively derived from mathematic axioms. It’s these consistent coincidences of measurement that define our meaning of “causality.”

In math, we can have two postulates, such as A=B and B=C. From that we can derive A=C. This sort of deductive causality is called implication. Strangely enough, the fact that germs cause disease is not derived from formal implication.

The (informal) “implication” is the coincidence of measurement. To many in the public outside of science, this might come as a surprise.  Without formal implication, technically the belief isn’t proven. So it might come as a surprise that “germs cause disease” has never formally been proven.

The “informal” implication is called p-value. It’s a measure of how likely a coincidence is to be random. If it’s unlikely, we say there is causality involved, effectively treating that “divergence from randomness” as formal implication.

The same goes outside of science. How do /you/ know germs cause disease? Either (a) by intuition, (b) by trusting others, or (c) by observing it yourself, though this is rare since the general public doesn’t have access to measuring tools that can detect germs, only the disease which coincides with contagiousness, that disease spreading from one individual to another via proximity. We assume some intermediary force carries that disease and we generally call that force “germs.”

As for intuition, our senses can give us a feeling of a lot more than just our immediate cognitive knowledge. That’s because during evolution, the human body learned certain adaptations (like not jumping off cliffs for example) that it needs no argument or evidence or proof to believe. Love for a child is the best example I can think of. Or parent. Or tribe. Maybe generally.

Trusting others, is hard. Generally (or often), for that, we need cause and effect that personally, directly affects us. But sometimes that cause and effect has nothing to do with what we are trusting, but who. Certain people, institutions, and sources that we have different reasons for trusting, but usually based on either personal relationships or societal ones, or the trust we have for the methods and practices that those sources (at least claim to) use.

Observation is a direct measurement. Ultimately, this is what scientists use, as well as trust in other scientists.

The measurements then are compared to existing presumptions to derive or estimate a “divergence from randomness” called a p-value. The fact that “germs cause disease” comes from germs being measured in the same time and location as disease consistently, together with potentially patterns that reproducibly transform one to the other.

Below, quickly, I've concretized something pretty elaborate: a form of p-value-like, Bayesian knowledge-acquisition rooted in frequency of coinciding measurements rather than direct probability. You can skip to "Ambiguity resolution" to get a gist for the core idea, but at least seeing "proximity" and the difference between "hypothesized scientific cause" and "hypothesized temporal scientific cause" is useful to understanding the last four paragraphs of this.

### Definitions

**Occurrence.** A time and location-defining-region.

**Elementary body.** A body whose only body is itself.

**Body.** A proximal occurrence of elementary bodies in time and location. (identity link)

**Coincidence.** A proximal occurrence of one or more bodies in time or location or identity. (evidential link)

**Coincidence of coincidences.** A proximal occurrence of coincidences in time or location or identity. (causal link)

**Hypothesized scientific cause.** Consistent coincidences of coincidences. (general scientific causal link)

**Hypothesized temporal scientific cause.** Consistent coincidences of coincidences in time, but not necessarily location, of specific identities. (standard scientific causal link)

**Consistency.** A ratio. The number of measurements a hypothesized scientific cause agrees with in proportion to the number of measurements a hypothesized scientific cause does not agree with. (likelihood of scientific model)

**Agreement.** The proximity between a measured body or coincidence and a hypothesized body or coincidence. (coincident predictiveness)

**Proximity.** A number between two locations, or between two points in time, designating their coordinate distance respectively; or between two identities, designating their dissimilarity of (a) occurrence, (b) body-composition, and/or (c) coincident-interaction; or between an identity and a location and/or time, designating the identity’s dependence on that location and/or time; or between two coincidences, designating the dissimilarity of their constituent bodies’ locations, times, and/or identities. (combinatorial, hierarchal, relational graph)

**Hypothesized scientific model.** Assignment of proximity scores between pairs of bodies and/or coincidences. (forces and interactions, and bodies, allowing the determination of consistency and therefore cause and effect)

**Temporal effect.** The temporally-later of at least one of the coincidences in a hypothesized temporal cause.

**Predicted effect.** The deduction of a temporal effect from a hypothesized scientific model based on coincident temporally-later proximities to measured bodies and/or coincidences. (modeling)

**Ambiguity resolution.** A hypothesized scientific model can have multiple ways of prioritizing proximity between bodies and/or coincidences. For example, what makes two coincidences more proximal? Their constituent bodies’ locations and times, or their constituent bodies' identities, or all three evenly? If you run into somebody you know right after thinking about them, that is a coincidence between a body and another coincidence: the body of your neurological process about another body, and the coincidence of your two bodies being at the same location. The identity of your neurological process (in your body, and as being about the other body) is proximal to the two identities of each of the two bodies. Thus, that body and coincidence consist of identities whose proximity is objectively more proximal than if they referred to the identities of the bodies of two different people, making it objectively a “bigger coincidence.” However, without a consistency of such coincidences — in location, time, and/or identity — a hypothesized scientific cause cannot be attributed to the coincidence. And without a consistency of such coincidences in the same chronological order and between the same two bodies — perhaps only varying in location — a hypothesized temporal scientific cause cannot be attributed to the coincidence.

However, these proximity scores are not provided by nature directly. A hypothesized scientific model defines them, but a hypothesized scientific model might be more right or less right, and in order to resolve the accuracy of a hypothesized scientific model, given that as an epistemological objective, a process is needed. (evolution of null hypothesis)

**Hypothesis accuracy.** Number and certainty of measurements, maximization of the consistency ratio. (null hypothesis criteria)

### Broader implications

**Scientific knowledge-acquisition.**

1. Hypothesized scientific model.
2. Measurements.  
3. Updated hypothesized scientific model based on consistency between proximity of measured coincidences.

This of course is how Bayesian belief systems work, though from a novel proximity-based formulation rather than probability, allowing for decomposition of coincidences into times, locations, and identities; but never mind that for now, and as for Bayesian belief (rather than 100% certainty), scientists generally are aware that this is the possibly-inescapable limitation of measurement-based scientific knowledge (as opposed to "I observe; therefore I'm observing", which can be known with 100% certainty, as well as what one is observing, remembering, sensing, feeling, and so forth).

In practice, which measurements are conducted must be prioritized due to resource and time constraints, for example by estimates of how certain or uncertain existing available data is, and the availability of the data, and weighing consistency ratios based on one’s estimated certainty of the corresponding data regarding those measurements.

**Is prediction necessary?**

Note: The big heresy here is that “prediction” doesn’t necessarily come into the picture at all. High-certainty data collected entirely accidentally is just as valid as equally-certainty data collected through the traditional scientific method process of predicting and intentionally reproducing predictions first.

This is a lot of definitions. Let’s go through an example to get a sense of how something like “germs cause disease” can be known, and without prediction, despite possibly your initial judgement:

“Germs cause disease”

1. Microscopes measure specific microorganisms (specific microorganisms that are actually later defined as “germs”) in diseased persons.
2. The diseased person is believed to be diseased based on reported wellbeing, visible symptoms, or measurements such as blood tests or urine samples.
3. This coincidence of measurement (1 and 2) is consistently measured with diseased persons. Sometimes a sequence of transformations is consistently measured as well that transforms germs to disease (1 to 2).

Somehow, we conclude that 1 is the cause, 2 is the effect, and 3 is the justification, without needing a further process beyond these 3 steps.

The scientific method is:

- Characterizations (observations, definitions, and measurements of the subject of inquiry)
- Hypotheses (theoretical, hypothetical explanations of observations and measurements of the subject)
- Predictions (inductive and deductive reasoning from the hypothesis or theory)
- Experiments (tests of all of the above)

(Source: “Scientific Method” - Wikipedia)

At first glance, these 4 bullets are actually quite different from the 3 measurement practices (knowledge-acquisition kernel) described earlier that determine the scientific knowledge-acquisition (epistemological) process that allows us to conclude that “germs cause disease.”

First let’s deconstruct why they appear different and show that the second (the scientific method) depends necessarily on the first (consistent coincident measurement, or “coincidence”).

Interestingly, the 3 steps are not a scientific method:

- Characterizations: person as diseased - step 2. 
- Hypotheses: existence of disease - step 2.
- Predictions: “microscope measurement would coincide disease with a potential cause” - an incentivizing motive for conducting step 1; however, step 1 could be plausibly conducted by accident, as is often the case for discoveries in science. Thus not included in the knowledge-acquisition kernel.
- Experiment: microscope measurement - step 1.  Result: existence of germs - step 1. Upon reproduction or across other such microscope measurements, same result - step 3. Perhaps a transforming sequence is measured repeatedly as well - step 3.

Those original 3 steps didn’t explicitly include a prediction. However, upon discovery of the germs, future experiments may now perhaps predict “germs coincide with disease”, or, also possible, stumble onto the same findings by accident.

Hypothetically, if N experiments stumbled onto the same findings by accident, taking the limit of N to infinity, would a prediction be necessary to know scientifically the conclusion of step 3? The answer is no. That’s why the knowledge-acquisition kernel of cause-effect-coincidence is perhaps more general to science scientifically. 

In reality, given already a sufficiently high N (let's say infinity to make the point) and high-quality data: a purposeful experiment which follows a purposeful prediction, is redundant and provides no information gain compared to the existing data, except perhaps on the role of purpose/human-intent in influencing the measurement. In the study of consciousness and wave-particle properties in quantum mechanics, this may be relevant, arguably. However, let’s look into that a bit closer as well to make sure we’re not conflating measurement intent and measurement bias.

If you guess that such a caveat would be such a conflation, you are right. If the measurement is carried out identically, with or without intent, and the result is the same, then intent is not relevant and is redundant. In quantum physics, detectors are used to measure which slit a particle may or may not have gone through. When the detector is active, a different pattern appears on the projection screen than if the detector is inactive, independent on the physicist’s intents or predictions.

Same with the microscope. If one were to investigate a sick person’s body with a microscope “for fun”, and hundreds others did the same and accidentally found measurements of germs, an additional replication of that experiment would psychologically add confidence to the experimenter, but data-centrically provide no information gain and would be redundant. 

That is, unless intent were a causal factor. In psychology experiments and sociology, this often may be the case, where intent is part of the measuring “device.” Thus a measurer’s intent or even knowledge that a measurement or experiment is being conducted can influence their measurement. In this case, there is an extra bias that has to be accounted for, making the experimental measurement actually less reliable than in-the-wild accidental stumblings, unless that bias is what’s secretly being measured. 

A prediction can at best be a bias, at worst be redundant. If it’s a bias, then at least we learn something about the nature of prediction. If it’s redundant, then scientifically its value may be zero but it can be attributed value for the subjective, psychological confidence of *control* it gives to scientists. “I have done this intentionally!” rather than “this is caused by this.”

<br>

> Utility depends on truth. Truth doesn’t always depend on utility. (Unless the truth is about the utility of something).<br>
>  &ensp;  — on the necessity of prediction

<br>

**What about a hypothesized scientific model that can account for hypothesized scientific causes?**

Note: Another heresy is that the standard scientific causality is defined as a special case of causality. While the standard model of physics can somewhat hypothesize about scientific temporal causes, it hasn’t much scratched the surface of non-local synchronous causes or causes whose identities are not as strictly proximal. These are called synchronicities and have been measured, though without demonstrated predictive power, in “datasets” documented throughout books, tomes, and anecdote.

In quantum physics there are believed to be many non-local effects and entanglements that aren’t strictly speaking temporally causal. 

Why our coincidence fixation is dependent on temporal and identity synchronicity/coincidence, and not a looser combination of location, time, and identity, is unjustified.

In my opinion, a 90% proximity between 10 coincidences in time and location, and only a 70% proximity in identity, is just as strong a form of coincidence as a 100% proximity between 10 coincidences in identity, 60% in time, and 2% in location.

That is, two particle accelerators on opposite sides of the Earth can measure the same particles, but with different statistics on the interactions, and vastly different locations on Earth. Yet if the particles are “kind of proximal[^1]”, their behavior is still unified, despite the variance of identity, under such properties as charge and mass and baryon number. But those values being associated together, to form a single particle, is itself a coincidence, and requires explanation. Similarly, while the identities of a neurological process are not exactly the same as one’s run-in with someone they were thinking about, some amount of chance has to be attributed to that coincidence as having a hypothesized scientific cause, beyond just the independent causes of its constituent bodies and coincidences. That amount depends on the consistency. For example, if one individual experiences many such precognitions and encounters, though not necessarily with the same individuals, the coincidence of coincidences is itself a coincidence, exponentiating the proximity of the constituent ones, unified by the identity of the individual, and exponentiating the consistency-demand of a hypothesized scientific model. Synchronicities can all be radically different, but if some individuals can report extraordinary ones, and numerous, and a model exists that can maximize the consistency of that meta-level of coincidence, given those measurements, while preserving the consistencies of the existing model, then that model has a higher hypothesis accuracy.

Such a model may for example be a coherence/decoherence model (probability collapse model) that singularizes consciousness into threads, answering both why a brain composed of many neurons can have a singularized experience and the nature of why a non-local, or distributed, interaction of consciousness such that, for example, an encounter with someone can be timed and planned together with them non-locally, could occur, while still adhering consistently to the measurements (including the doubt-casting ones[^2]) of the existing model, then that model is a superior hypothesized scientific model.

[^1]: w.r.t. identity, e.g. different flavors of neutrino, leptons, or hadrons
[^2]: "But Sam, short of there being some 'mysterious plan' or God, why wouldn't such powers in the universe give rise to greater benevolence? Why are there wars and terrible tragedies?" My answer right now: Well, short of those plans and "myserious ways" explanations, here's a pretty simple analogy: you have a cellphone and access to the internet, right? Therefore, you already can communicate non-locally with many people across the world. Perhaps the brain's mechanisms aren't even as powerful and can't even be experienced as consciously. If you don't end war and tragedy, how would they? Perhaps those subconscious communications happen in dream states and with more resource constraints, over the course of a much longer period of time. As for how, perhaps however your consciousness singularizes in the first place, is how it can distribute (neurons are not positioned in the same location either, and though they have chemical messengers, all a billion of them singularizing into experience isn't explicable by existing models). Now, if those forces somehow intervened nefariously, then questions would have to be asked about the safety of one's own subconscious to oneself, and if somebody else could hypothetically be held culpable. That would go into occult views however, and is not the most optimistic interpretation, if optimism can be a distinguishing metric in the hypothesis accuracy for a hypothesized scientific model as well, at least in explicability ties, formally (or other metrics, like beauty).
