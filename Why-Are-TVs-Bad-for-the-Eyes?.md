# Is Intense Polarized Light Worse for the Eyes than Intense Unpolarized Light? (Why Are TVs Bad for the Eyes?)

> This was my thought process:

## Light Behavior, and TVs

If light is a wave, then how do a camera’s sensors pick up any one point from any other? Is the probability so low for those other points? (Yes). But then how is the picture always not more blurry due to the obfuscation, or is the obfuscation also so low? (Yes). In a diffraction experiment, the light is projected randomly, and so the variation, combined with memory, is largely due to that, where dispersed spatial points on the projection screen are arrived to, even single photons thanks to the memory of the paths of the previous. 

Why would multi-head even be needed though? Perhaps it wouldn’t, aside from justifying the exploration of multiple paths as what causes electron energy level transitions to collapse. 

This coherence allows light to pass through walls at low frequencies, and interact, via EM momentum, at higher frequencies so as to undergo decoherence and not pass through walls at visible frequencies. 

But perhaps for the same reason TVs are more visible with polarized light (which undergoes more decoherence), that blurriness earlier mentioned does happen. 

Furthermore, it’s best to elaborate why the standard model predicts a fallacy in the possibilities of blurriness vs. no blurriness. The standard model, without a memory of the wave of the previous photon, cannot predict significant interference with the current photon as would be measured in a diffraction experiment unless such images are also blurry/obfuscated/dispersed-widely-like-wave in photos too, unless double slit experiments have only measured such interference patterns on scales of pixels, which is not the case (e.g., sunlight in a diffraction box). The interference is probably across photons, both in space and time due to memory. 

That wave pattern, with multi-heads, both makes this more efficient and allows for electron energy levels being discrete at approximately all given times. 

The question that I always find myself asking again is how the interference pattern persists at varying distances of the projection screen from the slits, if those interferences are in fixed locations. 

Another point is that the wave pattern, and multi-head, would involve severe destructive interference in image photographs, for both a camera or the eyes. What prevents that destructive interference? Perhaps, without specific slits, the probabilities all interfere equally and thereby preserve the original general distribution. So what I wrote earlier about the standard model would be wrong, if the math of interference does not predict much anyway for arbitrary camera setups. 

The interference is too uniform I suppose. 

Then polarized doesn’t matter at all for TVs, and why does it if this phenomena is not generally measured by cameras and the eyes?

Regarding the first question, of why the interference pattern persists over varying distances of the projection screen from the slits, my theory accumulates the probabilities such that they persist over their temporal interferences. This should result in the same pattern…

So, this is theorized to happen independent of the multi-heads—then Huygen’s principle isn’t especially necessary to the theory, only a principle that allows multi-heads to be non-contradicting to the expected pattern. 

Well, the photons can’t be expected to bounce off the slits at every angle as if dispersing like waves, so multi-head probabilities are necessary for that pattern. Nevertheless, the “bounced” probabilities should be highest, unless they are avoided due to coherence. 

Okay, then that seems plausible. Coherence causes the multi-heads to behave like Huygen’s principle, and memory enables that to work for single photons, and persistence enables that to work at varying distances of the projection screen from the slits. 

But then the angle most collinear with the light source would have the highest probability. The light source, I think, isn’t necessarily parallel with the slits—but I’m not sure—it might be. I have to look up some setups, including the big sunlight box one. My guess is no. That being said, passing through at any angle other than parallel might be impossible due to the depth of the slit boundary and the increasing likelihood of a “bounced” happening, the bounces now, in this theory, being considered avoided by the coherent light, for the same earlier described reason walls are travelled through—though wouldn’t visible light betray this? Wouldn’t it interact through EM with the barrier enough to undergo decoherence and not pass through like a wave? Isn’t that also equally problematic in the standard model?

Question: What stops a light wave from becoming decoherence due to collision with the slit boundary? After all, visible light cannot pass through the atomic gaps of walls. 

But maybe the difference is the scale. Those atomic gaps are much smaller than the boundary slits, so the interaction becomes impossible to avoid for any of the visible light heads. This is not the case with the wider boundary slits, and therefore Huygen’s principle applies. 

So the theory is, the “bounced” is avoided. The slits are deep and thin enough that the photons can largely be considered to pass parallel through them. Then Huygen’s principle takes care of the rest in producing the expected pattern on the projection screen, together with memory and persistence for the more general cases of single photon and varying projection screen distance from slits. 

Then that blurriness, due to Huygen’s principle, becomes more of a risk with coherent light. Polarizing light from TVs perhaps induces decoherence. 

But then why are ordinary objects visible without this blurriness? The light has undergone no more decoherence than that from a hypothetical unpolarized TV pixel.  

Oh, maybe unpolarized isn’t less visible, but just polarizing is mechanically necessary to blocking out certain emitted RGB hues and not others as a kind of open-close logic gate on the RGB hues of the pixel, to enable color control (or black and white control, perhaps, e.g., by blocking white or allowing white to pass). 

Brightness of each hue. 

Meanwhile, there’s a backlight that’s just always on all the time, its point projections regulated by the polarizing filters of each pixel. 

CRT televisions apparently don’t do this. They should electrons at phosphor I guess. But risk sometimes emitting X-Rays, not just visible light, and therefore being also bad for the eyes. 

Plasma TVs are basically fire. https://www.explainthatstuff.com/plasmatv.html But I’m not sure if they undergo a polarization phase typically, though if they do, that doesn’t seem necessary. My old TV was plasma, most likely. Around 2010, manufacturers pretty much all switched to LED because of cheaper production, but not better quality. Plasmas seem to be better for eye health, but studies seem to be sparse. https://archive.nytimes.com/bits.blogs.nytimes.com/2007/01/10/watch-a-plasma-tvfor-your-health/#:~:text=TVs%2C%20which%20are%20brighter%20than,the%20risk%20of%20eye%20strain. No, actually, this seems pretty well validated. https://digitalsmarthomes.com/vancouver_canada/files/How-watching-TV-on-an-LCD-Plasma-and-Projectors-effect-your-eyes.html Plasmas probably don’t use polarizers. My TV was plasma. 

The fire comparison is maybe off—fire gasses undergo less ionization than what is typically defined for a plasma, but the concepts are related. Perhaps plasmas are more typically thought of as not self-sustaining reactions, in the general sense, like combustion is, e.g., requiring electric flow or some other not necessarily oxygen-involving reaction to produce the reconfigurations of electrons in that gas. 

Wait no — my TV was an LCD. 

LCDs, LEDs, and OLEDs all use color filters (polarizers). 

Maybe plasma is just fire but not constrained to oxygen (oxidation) based reactions. 

The sun is plasma. 

Ionized (electron excess or deficit) gas.

## Light Behavior, and Projectors, Mirrors, and Illuminated Objects

But then there’s the question how projectors work—after all, their projected colors are preserved

That means they’re not absorbed by the wall or the screen, or else they would illuminate 

But they perfectly reflect 

Like light from a mirror would

And in a point respective way or else each pixel would diffuse into a wave blur—or maybe that’s just its velocity, preserving the origin bounce

So then there is no need for a bounce—a wave suffices from each point of the projector screen or mirror, as long as velocity is measurable by a camera or the eyes

But then how do cameras/eyes work—do they have tubes that only let in light of corresponding velocities? If not, how do all photons not reach all camera/eye points? Maybe the probability is just highest for the most opposite velocity wave front—but why would the photon from the right not reach the camera/eye points on the left of the lens/eye? Proximity perhaps, but then why is peripheral vision so wide—the points most proximal to the lens/eye are quite narrow—the size of the lens/eye. 

So most likely the lens/eye has to curve in such a way that it only allows photons of certain velocities. 

Then those interact with the lens/eye and collapse as visible images, with those velocities corresponding with the points on the projector screen or mirror since the velocities most probabilistically point opposite their origin, and every photon whose velocity doesn’t has undergone some many divergences making it a less probable photon to collapse on the lens/eye than the one whose origin was directly across and along the trajectory of its velocity. 

In any case, it’s not necessary for the photons to bounce precisely like billiard balls. It suffices for them to diffuse like waves from their origin points as long as the lens/eye can filter the velocity—but wait, then a wave traveling rightward from the right of the projector screen or mirror might be picked up by the left “tube” of the lens/eye. Proximity is somehow also controlled for. 

[Radiohead’s “Everything In Its Right Place” is playing]

Either way, there is a difference between illumination and reflection

An object is illuminated—its electrons absorb the light and emit their own—this would most plausibly happen as diffuse waves not reflecting the angle of the light source 

A projector screen or mirror is reflected from—this does not involve illumination. For example, my wall’s discolored white is barely visible behind the projector lumens reflecting off of it when shined from a projector. These perhaps also diffuse as waves not remembering the original angle—but somehow are decoded by a camera/eye according to their origin point

Well, to the earlier point—the velocity of the wave to the right wouldn’t be rightward from the left of the lens/eye—its velocity always points to the origin no matter where it lands—and the left point on the lens/eye is somehow constrained to only accept left-directional velocities

So the question remaining is how lens/eyes control for velocities—do they use directional tubes of some kind?

And another question is Huygen’s principle doesn’t compromise the velocity of the wave front—well, the answer to that is probabilistic—Huygen’s principle wavefronts start uniform from their diffusion from the projector screen, wall, or object, and remain most probable along the velocities corresponding with the wavefront 

But it’s hard to imagine why there wouldn’t be some blurring as a result of this—there’d expectedly be some velocity compromising from each Huygen front, e.g., a rightward one on a rightward-originating wave on the left side of the lens/eye—less likely, but some blur would happen sometimes—unless the wave had come from many photons and the heads themselves were highly undergone decoherence—that’s most likely—the projector screen, wall, and object reflect or emit photons that have undergone a high degree of decoherence 

So Huygen’s principle is sort of negligible 

The interactions, especially in the visible spectrum, make this likely somehow in some but not all cases. Projector screens, walls, mirrors, objects, yes. But diffraction gratings, no. Perhaps the difference is scale and interaction type. With projector screen or wall light from a movie projector, the scale is bigger and light intensity maybe higher, and the interaction gap is much smaller, at the atomic scale of the atoms of the bouncing surface rather than at the macro scale of diffraction gratings slits. The diffraction grating slits are much bigger gaps and allow for more coherence than the movie projector screen or wall. The mirror, the same. Illuminated objects, it’s probably to do with the electron (atomic spectra) emissions from those objects—photons in every direction, sure—uniformly—but each actually originating with really high decoherence from their emission from the electrons of the atoms of those objects—and therefore ~~Huygen’s principle becomes negligible and~~ they diffuse mostly with velocities along the trajectory of their origin, decodable by a lens/eye. 

So the question is how the lens/eye filters for velocity. Do they have directional tubes that kind of absorb any photons that strike their edges and thereby only allow those to pass that align with their direction, that direction being pointed proportionally in the direction of where that image point should be receiving photons from?

How is this achieved in lenses and eyes? (Or some other method?)

Well, there’s one more question first—why does light diffuse so much, so randomly, so uniformly from every point it strikes?

From illuminated objects, that’s no mystery. They emit in every which way. 

From projectors screens/walls or mirrors, that’s harder to imagine. The photon should bounce according to the angle it strikes but instead diffuses.

Maybe it gets temporarily absorbed, changes the hypothetical energy level of the electron, and hypothetically gets emitted, but since the electron’s probability isn’t sufficiently high for that intermediary energy level, the photon preserves its original frequency without the hypothetical change. However, one flaw—the projector screen/wall gets more than enough light energy to emit its own color, so actually the absorption can’t have happened. The photons must have bounced, perhaps randomized in direction by a temporary electromagnetic dance with all of the electrons, maybe beyond even the first atom that it strikes, and, depending on the thickness of the surface/wall, most plausibly ends up repelling back as if a bounce—but randomly distributed because of that dance. 

That is why intensity is so important—to get that distribution quite uniform and prioritized compared to surrounding light. 

## How Digital Cameras Work

My original description:

> ### $\Huge &#8220;$
> Photodiodes are cool. They work by using the "conduct-ability" (conductiveness?) of electrons in excited states (since those electrons are less strongly held to the nucleus due to being further away).
>
> Then when light excites the atoms, I guess some anode-cathode pair (diode) called a photodiode accentuates the tendency for those excited electrons to escape orbit, and they end up creating electrical current as a result. I think the diode effectively creates a charge gradient basically, thereby accentuating that conduction.
>
> Same as film, photodiodes rely on the light's absorption by electrons, not antennas. I guess absorbent conductive elements like silicon or germanium can be used.
>
> Color filters can be used to filter which colors get through to excite said atoms/electrons.
>
> The different voltages (from the conducting electrons) for red, green, and blue spectrum-biasing color filters can be digitally interpolated to digitally infer what color of light arrived at that pixel, same as photopsins in our eyes. Each pixel corresponds to a location on the image.
> ### $\Huge &#8221;$

The only thing that’s missing from this description is how the light that arrives to each pixel/photopsin is the light from the desired origin direction. After all, light’s a wave, so it gets distributed everywhere and in all directions, so the fact that it arrives to the pixel/photopsin corresponding with its origin is non-obvious. 

Because that’s how the lens focuses the light, I guess—but wouldn’t this still work without a lens? No! https://youtu.be/A6TlcI4dH6Y?si=CMpOk5WpvxQY59vi This tracks!

Maybe this is just what all glass does? No, because glass is see-through at variable angles. What about a lens? How does a lens look at varying angles?

As for how the eye achieves this, maybe: “When we look at an object, the light that is reflected off of the object enters the eye through the clear front layer of the eye, called the cornea. The cornea bends the light before it passes through a watery substance that fills the area behind the cornea, called the aqueous humor.” ([How Does the Eye Work? - Optometrists.org](https://www.optometrists.org/general-practice-optometry/guide-to-eye-health/how-does-the-eye-work/#:~:text=When%20we%20look%20at%20an,cornea%2C%20called%20the%20aqueous%20humor.)) and “The cornea is shaped like a dome and bends light to help the eye focus.” ([National Eye Institute (.gov)https://www.nei.nih.gov › how-ey...How the Eyes Work](https://www.nei.nih.gov/learn-about-eye-health/healthy-vision/how-eyes-work))

“Some of this light enters the eye through an opening called the pupil (PYOO-pul). The iris (the colored part of the eye) controls how much light the pupil lets in.
Next, light passes through the lens (a clear inner part of the eye). The lens works together with the cornea to focus light correctly on the retina.  When light hits the retina (a light-sensitive layer of tissue at the back of the eye), special cells called photoreceptors turn the light into electrical signals.
These electrical signals travel from the retina through the optic nerve to the brain. Then the brain turns the signals into the images you see.”

Photopsins are photoreceptors.

Back to the earlier question, if that were all that glass did, the eye would see it as if it let through only the respective angle of light, and it would have a definitive front and back. Instead, light fully travels through. What about a lens? Does a lens, only allow through the light towards which it’s facing, with a defined front and back?

Well, the eye would see glass as it would were there no glass, if the light that exited were unchanged from the light that arrived, but wave behavior means that the glass does not filter the photons based on velocity, I think, so the light that arrives is the same as the light that exits.

But as long as the lens/cornea somehow refract light into the corresponding pixels, then it doesn’t matter—that’s what they do… somehow.

A lens refracts light originating from the desired direction into the corresponding pixel.  

But how does it do that if light is a wave? Would the probability of blur be non-zero due to photons possibly occupying any point in the lens?

Their waves put the probability of each photon’s location as distributed unless Huygens principle becomes negligible due to the wave nature largely having conceded to the particle nature due to decoherence from the originating source object. 

Well, that’s what I originally landed on—“negligible” except in diffraction grating experiments because the slots are wide enough in scale, as opposed to the atomic gaping projector screens/walls, mirrors, and other reflection surfaces, by which decoherence is induced. 

For some reason decoherence isn’t induced in the oxygen though of the diffraction grating experiments for this same reason. 

If that had an explanation, there’d still be the question how projector photons reach the point locations of the projector screen/walls rather than also diffusing more coherently over a wider distribution.
That’s probably because the probability of not hitting anything is too low, since there’s a projector screen/wall in the way no matter what, short of doing a full 180 mid-flight, so the most probable locations get sampled, being non-diffuse possibly due to the increasingly higher probability of landing/arriving at that expected point with higher intensity (more photons to sample perceived image based on), although that would require filtering by the eyes, so more likely the projected photons actually arrive at the expected points and that’s where they get sampled, probably because the kinds of wave like patterns found in diffraction grating experiments are on smaller scales where the travel probabilistically appears more diffuse. 

Maybe, when there’s no way around collapse, the photons collapse very strongly to the highest probability, but when there’s even a slim chance—as through/around oxygen or the slits in a diffraction grating—Huygen’s principle still branches very strongly—non-negligibly. 

Though, then the photons would just travel around the camera and person. So the bounce off the diffraction grating slit happens too, just not so much as to induce decoherence. 

That decoherence is probably induced by electron absorptions, not electron reflections/repulsions/dances. That way, a particle appears on the film strip, but the heads don’t just avoid and go around the film strip. 

It’s strange though that things aren’t blurrier then, as each pixel/photopsin might measure a photon that does not corresponding to the desired originating direction. 

The lens itself might refract the photons originating from the incongruent directions. 

Maybe during the process of refraction, the likelihoods exponentiate. 

So the different heads survive, but the most velocity divergent get seriously truncated and it’s as if each photon had traveled as a particle in a straight line, or otherwise missed the clearing to make it into the lens/cornea at an angle that hits the sensor or optic nerve. 

Maybe the angles of the lens to camera, eye to phopsins make it unlikely for a straight-line trajectory of a photon to originate from a direction that corresponds with the wrong pixel. 

I still have trouble seeing this because a photon can do that, in a straight line. What stops that blur?

How does a photon strike the right pixel?

Maybe the eyes have tubes like I imagined. Maybe a lens is just bigger than a sensor and photons have to strike it at the right angles to ever reach the sensor. 

Or maybe the right-pixel angle is the one closest to the wave front and is struck first by that photon before the photon’s wave reaches the surrounding region. So that’s where it collapses. 

Think of a photon going in every direction from an origin. The closest path to the lens is the one that is most likely to have decoherence induce a collapse of the wave into a particle at that location. That closest path isn’t necessarily the expected angle. Any scene to the right, for example, would be closest to the furthered right side of the lens. 

How does a pixel of a camera sensor that a photon strikes correspond to the direction from which it originated?

A lens is designed such that it doesn’t transport any other light to the pixel directly ahead, e.g., of the camera sensor. 

How are non-corresponding photons filtered out? 

What does the glass of a lens do for example?

What about the cornea or lens of the eye?

A lens points in every direction, and says, “I only accept photons from over there. I only accept photons from over there. I only accept photons from over there.” Glass doesn’t do that. Glass lets all photons pass through. How does glass become a lens? That’s a huge difference. 

Otherwise, the camera sensor would be flooded with photons from all directions at all <!--(each individual)--> pixels. 

A straight line from any photon origin point farther away can reach almost every point on the lens, and therefore, if not filtered by that lens pointing and going, “I do not accept you,” reaches every pixel on the camera sensor, creating a white image, as would happen with no lens or with glass. 

But how does a lens do that if it’s essentially made from glass, which does no such discrimination? 

Glass allows photons from every direction to exit as they arrive. 

That would include—no?—the photons that arrive at different points on the glass, but originate from the same point location. The lenses in our eyes—cornea and the whole biology—then point and filter somehow, the photons having arrived with perhaps velocities unaffected by the glass, and therefore velocities still pointing back to the origin direction, with points on the eyes corresponding each with only one such direction. 

A lens must therefore somehow sense velocity differently per location. 

A glass has no perception of velocity to filter between, so the question is, how does such appear in a lens?

How is a lens manufactured?

#

Note: OLEDs aren’t necessarily polarized. They emit their own light. They’re sometimes (usually, 2024) polarized. I don’t know if plasmas are usually polarized. 

#

What are the quantum properties of a lens that allow light to be focused from a specific originating direction to a specific pixel on the camera sensor?

Note that light can reach many or all parts of the lens from the same originating direction.

## Bring Back Plasma TVs, or "QD-OLEDs Seem Like They Might Be Cool"

Eyesight in children is deteriorating. The percentage of children who depend on glasses has gone up _ since _. The percentage of adults who depend on glasses has gone up _ since _. 

Vision problems cause more than just headaches. The physical effect on the brain of blurry vision, including from just the headaches or migraines that are medically known to result, can induce everything from brain fog to anxiety to more. These physical and psychological consequences can be the early starts of small problems that snowball into much bigger ones, with no limit to the exponentiating possible avalanching, as is always the case with deteriorations that are induced at extremely young ages. 

One simple way to reduce the severity of this problem, which has most likely scaled due to the abundance of screen technologies that are shown to cause eye strain and impair vision, is to use screen technologies whose light is more similar to that of bright environments whose image in front of us—while being full HD and any arbitrary scale of resolution, full of contrast—don’t damage our eyes—such as forests, woods, lakes. 

A child can stare at these environments all day every day and not suffer vision loss—why is that? The picture quality is perfect. They’re bright, illuminated by the pretty impressive lumens of the sun. They’re just light beams. What’s the difference? What attributes do those photons have that are different from those of LCD and LED screens, the kinds that are used today?

Well, one could argue people blink less while staring at screens due to the immersion of the content or the fixed position of the light source. That seems like a reasonable attribute to blame, if not for the fact that the real world is often very immersive without causing eye strain and, as for lack of as much eye movement, perhaps that’s the main difference that’s causing huge levels of eye deterioration from early age, but there are candle meditations where people stare at candle flame for an hour a day and I guess that could be studied about whether that causes vision loss. There are sights in nature that do not severely cause eyesight deterioration despite being fixed in position—watching the sunset each evening is probably not as detrimental to the eyes as the same time spent on an equally bright screen—but who knows?

Well, the study data does give some hint to this. 

Plasma TVs, whose emitted light is more like natural light due to the lack of polarizers, which are used to control the color in each pixel in LCD and LED TVs, are shown to cause less eye strain and eyesight damage, despite having had better picture quality. [Nope: This comes from anecdotal reports. No study has been conducted]

Now, there can be other hypotheses besides polarization as being the main difference. Plasma TVs have deeper blacks but sometimes not as bright whites. They might also—and this is conjecture—have less blue light. The second point isn’t shown anywhere, but the first point—less brightness—might be the reason. 

That would be a good explanation if not for the brightness of the outdoors. Fire, for example, close to being a plasma itself (arguably a plasma), is quite safe to look at each evening. 

Most likely, the additive electromagnetic field of polarized light has a deleterious effect on the eyes. In unpolarized light, more of the electromagnetic field gets cancelled out due to the uniform distribution of the field vector directions. 

Whether the smaller electromagnetic fields of radio waves, used to transmit WiFi and cell signals, has an interaction with the eyes or brain, isn’t the point here—the EM fields of polarized *visible* light are much bigger and not ordinarily found in such intensity in nature as in LCD and LED TVs. Given that plasma TVs are data-centrically shown to be safer on the eyes, emitting light the way the gasses of the sun or a fire might, and their better picture quality, one might wonder why they were discontinued by all TV manufacturers around 2013. 

The main reason is production cost. LCD and LED screens just became cheaper to make, and caught up in terms of picture quality. Furthermore, phone and tablet screens have never been built with plasma technology—it might be impossible, according to the existing skeptics, and I’m not proposing any method otherwise (well, aside from possibly “unpolarizing” LCD and LED technologies, e.g., by emitting more directions of polarization per pixel [or what the extremely-expensive QD-OLEDs do, as of 2022]). 

The power consumption of plasmas is also higher, creating little fires in each pixel. 

But for eyesight, and given their competitive or better picture quality, I think plasma TVs should be researched and developed again. They can be marketed, with scientific evidence backing the claim, as healthier. 

It’s a small change, but can save vision in a world when vision is deteriorating at epidemic proportions, most of which has concentrated in the last _ years (around when CRT screen technologies, which aren’t good for the eyes potentially due to possible X-Ray radiation but which don’t use polarizers, were replaced with LCDs and LEDs, and plasmas). [Fact check last part]

My polarization hypothesis comes from the fact that of all of the attributes of light that are different between TVs and natural outdoor light, the most extreme is polarization. 

Illuminated objects absorb light, their electrons are excited, and depending on their atomic spectra (pigments), they emit unpolarized light in the color that one sees. Tree bark, for example, emits brown. Grass emits green. And so on. The picture quality is great. One can stare at a tree all day. One can even stare at a blue flower all day. All of this light is, for the most part, unpolarized.

The sunlight that’s absorbed itself is unpolarized. 

The kind of light from lightbulbs usually used in lamps is unpolarized. 

Screen technology, disproportionately, hurts vision, because the carrier of those lights—photons—supposedly need to be different than those of outdoor light. Why? Is a mountain range not high enough definition for somebody? Are the Northern Lights (some of which do partially polarize due to Earth’s magnetic field) lacking contrast? Is a fire too dim?

The most plausible culprit that cannot be attributed to the majority of the HD views of nature, is polarization, and the resulting intense electromagnetic field of polarized light in the visible range frequency is probably the source of the damage to eyes. 

Note: OLEDs aren’t inherently polarized, but are polarized in practice in order to improve visibility in daytime/sunny conditions. There are no OLED TVs on the market that don’t do this, as far as I know, but [polarizer-less OLEDs are in development](https://www.oled-info.com/here-come-samsung-polarizer-free-pol-less-oleds), [not yet on the market](https://www.oled-info.com/tags/polarizer-free-oled).  QD-OLEDs are unpolarized, as it turns out, which came out as far back as 2022 [it's 2024], and cost thousands of dollars, whereas plasmas are sold on Facebook Marketplace for under $100, but in both cases the impact of polarization to eye health is not known. 

[LG touts better eye health for different reasons, but also worth noting that those same TVs aren’t linearly polarized, but [circularly polarized.](https://www.displaymate.com/LG_OLED_TV_ShootOut_1.htm) “together with circular polarizers that suppress light reflections” — so the difference win polarization is consistent with the observed or touted eye health difference difference, though plasmas still have that reputation historically perhaps more formidably and are neither linearly nor circularly polarized (unpolarized). 

https://www.lg.com/in/oled-tvs/2021/eyecomfort-ecofriendly/#:~:text=LG%20OLED%20TVs%20are%20also,developed%20by%20TUV%2DEyesafe®.

QLEDs also use polarizers, are like LEDs bit with QDs just added 

## Testing of Hypothesis

Though both plasmas and OLEDs are marketed as easier on the eyes, the latter also less linearly polarized than LEDs, intense polarization has not yet been researched in control studies as an optically dangerous property of the visible light spectrum, which is a higher frequency and has a stronger electromagnetic field than radio waves, making this hypothesis somewhat—though not entirely—independent from concerns over 5g, which are also polarized wave signals, but at a much lower frequency, though perhaps higher intensity. The increase in eye damage over the last couple of decades and the study data that screen technologies are deleterious to vision make this hypothesis more of concern to optometry. A simple study to falsify this hypothesis is to put volunteers in an environment to practice a blue flower meditation—staring at a blue flower in the sun or under an ordinary incandescent lamp for prolonged periods of time, perhaps days or weeks—and compare the reported eye strain, itchiness, dryness, and other symptoms to the same but for a screen image of a blue flower with a different cohort. Lighting conditions can be normalized so that the real-world flower is as illuminated as the on-screen one, by comparing still photographic images of the two so to achieve equal perceptual intensity of the flowers, natural and digital, and then lux meter intensity can also be measured and equalized.

Different cohorts can be assigned different screens. My prediction is the unpolarized blue flowers will have the least damaging effect on eyes, despite all other known attributes of light being held equal across the different cohorts. The color “blue” is chosen for the flower to control for the possibility that blue light is the cause of the eye damage, as hypothesized by other works. All sessions should be conducted during the same hours in the day. If no eye strain is reported for *any* of the screen technologies, then the staring time was not long enough, since screens almost definitely contribute to eye strain—a discovery otherwise would also be novel. Other causes of damage to consider are flickering, and intensity surface area. With a blue flower, perhaps only the blue flower is brightly illuminated. With a TV, the environment of that blue flower should match the color field of that of the natural blue flower.

The high intensity of screens would seem to be the main culprit, but an outdoor environment is “higher resolution” than any TV, “sharper,” has “better contrast,” and is equally bright or brighter (“intensity”), including a blue flower, so the difference between the photons of one and another doesn’t have an attributable measured or evidenced attribute of light in any theory. Then intensity should not be the reason why screens damage eyes, unless the light can somehow be distinguished at the quantum and electrodynamic level, between a blue flower on one and a blue flower from another. The only culprit remaining is polarization, most likely, or screen lights possess some property of light not theoretically known, for example, if quantum decoherence somehow has an interaction with eye health and is different from screens.

My guess is, the combined intensity and polarization is the cause of the damage. When polarizers reduce intensity, I would expect that to reduce damage. When intensity is high and polarization is high, I would expect that to increase damage, over an equally intense unpolarized setting. Controlling for intensity is necessary to this study. 

Even if polarization becomes evidenced strongly against as a contributor to this difference, there is no known attribute of light that distinguishes photons from a screen and photons from a natural environment if the latter at least as intense, besides polarization, raising the research question how it’s possible that one can stare from atop a mountain range all day, or at a blue flower, or even watch the clouds or lake, and not suffer the same eye damage as from screens.

Others have proposed that the damage from screens comes from using them outside of daylight hours, or due to the relatively fixed focus of the eyes. This is likely, but it seems likely also that staring at a screen all day—even during daylight hours only—would still be damaging to the eyes, while also seeming likely that a blue flower meditation, in which one keeps their gaze and focus fixed (on a natural bright blue flower on a sunny day outdoors under bright sunlight), would not cause the same extent of retina damage (if any) as having occurred from screens in daytime conditions—having accelerated over just the last couple decades. (from a similar environment depicted on a screen, photons all being equal). 

Polarized light is often found harmful in the form of horizontal light due to that being the more ubiquitous form of intense light in nature, since light that bounces off surfaces can often polarize horizontally. Polarized sunglasses can actually reduce this intensity by filtering out the horizontal polarizations and allowing the less-intense vertical ones, but this shows the impact that the combination of intensity and polarization can have, since horizontal light is a known cause of eye strain with an entire sunglasses industry profiting from that fact. The same intensity unpolarized is not known to be as destructive. 

Actually, I think the reason TVs are worse is because they’re more intense. They have to be since they have their own colors—black for example, a black screen. The atoms absorb light and emit the natural color of the material. The TV light then has to compete against its own color. So amid electron absorptions and emissions in the material of the TV producing ordinary object color is also the TV pixel light—LCD or plasma or QD-OLED or whatever—and the latter has to outshine the former as well as all reflections. Reflections from daylight or indoor lighting can cause natural glare against the material of the TV independent (or possibly not) of the created light of the TV’s pixels. So higher intensity is needed. 

Higher intensity is bad for vision. Staring at the sun, or maybe even a fire, for a long time, is bad for the eyes. 

The solution is electronic ink. 

[or somehow getting glass to emit colors through spooky impossible/causal action at a distance]. 
- Put a QD-OLED screen in the back of a box TV and fill the rest with glass<sup>TM</sup>. Should be no different from staring out a window.
- Or use projector light, deflect it through mirrors out of a window/"portal"<sup>TM</sup>.
  - in a box-like frame
  - projection screen in the back (no glares/reflections)
  - with or without mirrors
  - "movie theater in a box" ("portal"), TVs that aren't bad for kids' eyes
  - The "portal" is either the box or the glass screen (in the front of the box)

Polarization + intensity would result in a bigger EM field, and the impact or harm of that from visible light frequencies (where the EM magnitude is much bigger than at radio frequencies like what’s used in 5G) is unknown, since while people are worried about 5G, much stronger EM signals are passing through LCD, LED, OLED, and QLED TVs every day. If those aren’t harmful to eyes or brain, the former really probably aren’t, especially as both cell towers and TVs emit at disproportionately high intensities, the latter from closer proximity (and therefore higher intensity per surrounding surface area). So if 5G is a concern, then regular TVs are a much bigger concern. Most likely, the EM field isn’t harmful, though the brain itself both affects and is affected by EM fields internally and externally—including those common in horizontally polarized natural light as evolved with in nature by humans, and whose frequencies and EM magnitudes are higher than those of cell tower emissions. This bodes well for the health concerns around 5G and the future of such technology, though perhaps neural networks could still make the encoding schemes more efficient and allow energy and power consumption savings from lower frequency emissions and higher efficiency encoding schemes based on neural encoders and decoders with respect to the information encoded in the wave modulations. Other than that, 5G is the future. Hopefully this reduces some paranoia. 

### Reducing Paranoia

TVs emit a much higher electromagnetic frequency and at a higher intensity per surrounding the-usual-human-distance surface area. If 5g is dangerous, then regular TVs are far more dangerous. But don’t worry, because horizontally polarized visible light is common in nature, and can be even more intense and having a much higher electromagnetic frequency than 5g. 

While people are worried about 5g, much stronger EM signals are passing through LCD, LED, OLED, and QLED TVs every day. If those aren’t harmful to brain, the former really probably aren’t, especially as both cell towers and TVs emit at disproportionately high intensities, the latter from closer proximity (and therefore higher intensity per surrounding surface area). So if 5G is a concern, then regular TVs are a much bigger concern. Most likely, the EM field isn’t harmful, though the brain itself both affects and is affected by EM fields internally and externally—including those common in horizontally polarized natural light as evolved with in nature by humans, and whose frequencies and EM magnitudes are higher than those of cell tower emissions. That coevolution means biology has probably evolved a big adaptability—though radio waves interact with antennas whereas higher frequency waves in the visible light spectrum don't affect antennas, and yet higher frequency light, in the X-ray spectrum, are known to partially go through the body. Longitudinal studies lacking, the health safety of both radio and visible still is a reasonable null hypothesis. EEGs and transcranial magnetic stimulation working as technologies though does prove the extreme output/input relationship of the brain to electromagnetic signals (though at different frequencies/momenta, respectively). 

The risks of TV screens on the eyes might suggest that electromagnetic signals can be dangerous to biology at high intensities and/or high polarizations. That’s true, but the sun produces higher intensities, and horizontally polarized glares in nature such as from lakes are perhaps comparable as carrying photons with the same nature/quantum attributes (including additive electromagnetic fields, though besides some possible unknown decoherence difference). CRT, Plasma, and QD-OLED TVs have lower electromagnetic field magnitudes due to their exclusion of polarizing filters, meaning the randomized polarization outputs sum their conflicting electromagnetic forces to a lower electromagnetic total, by Newton’s second law, regarding the polarization difference. 

This bodes well for the health safety beliefs around 5g and the future of such technology, though perhaps neural networks could still make the encoding schemes more efficient and allow energy and power consumption savings from lower frequency emissions and higher efficiency encoding schemes based on neural encoders and decoders with respect to the wave modulation information encoding scheme as neurally wave-modulated<sup>TM</sup>. Then that would possibly make much of the 5g infrastructure redundant and energy-wasteful. Other than that, 5g is a reasonable future. Hopefully that reduces some paranoia. 

## Mass Production of Mass Production / Anti-Homogenization / Anti-Monopolization

For just aesthetic reasons, I suggest bringing back swivel stands for TVs and more-creative/less-homogenized frame designs for TVs, as mass production with AI is only going to increase the risk of homogenization in manufacturing, and possibly the monopolization of mass production tools. 

For more serious reasons, I suggest attention to the issue of homogenization and the lack of vendors and competition of mass production technologies, which are becoming ever more monopolized and capitalism’s choices becoming narrower, more controlled and less creative.  

When AIs can manufacture TVs without workers, the big tech companies need to mass produce mass production technologies, technologies that are built to build. 

Then the small stores can build their own TVs and so on. 

I suppose besides being an economic issue, it’s a psychological issue because homogenized mass productions of products has led to less choice in capitalism, less individuality, less self expressivity, and less novelty in one’s local stores and use of skills of individual creator talents. AI has the potential to make mass production technologies affordable to smaller stores, not just big manufacturers, and then more novelty TVs and other technologies and products can be built, but only if those producing technologies are sold, and ideally with competition driving their efficacy in helping generate manufactured items, much like generative art AIs are doing so to art, except without the moral downside—almost. 

Like certain weapons, automation technologies should sometimes require background checks. But otherwise, they should be developed and distributed on the free market rather than homogenized and concentrated in a handful of worker-less tech corporations. 

Compare the variety of CRT box TVs and earlier 2000s flat screens compared to TVs today.

Though in terms of physical appearance, the best is the July, 2009 32" LG LH20, LED TV, that I got (my mom paid for) in 2009, as a kid—well researched (by me, and selected by me) and better than my friend’s Samsung who got his around the same time without as much research and price consideration. 

The LG characteristic on the bottom right that powers up with a kind of swerving light pattern, on the LH20 one, is what I mean by creative frame designs, and is the best part, can’t find that kind of design touch anymore in the 2024 homogeny, I think—maybe I’m biased. Either way, the mass production technologies are all concentrated into a handful of manufacturers and small store owners, especially as AI has the potential to streamline the process further, should be able to get in on the action, or else Marx’s "means of production" won’t just be not controlled by the workers—it won’t even be controlled by the capitalists. Only the oligarchs. 

#


 that would be a cheaper, faster, more cost-effective way to study or commercialize unpolarized TV.

Note note: I don’t know if the same isn’t true for some plasmas. 

Best way to find out if your TV is linearly polarized is to look through a pair of sunglasses at different angles to your TV and see if the visibility of the screen image changes through them. 

Never mind, this might not hold if TV circularly polarized. 

[Find out how to do a circular polarization test]



